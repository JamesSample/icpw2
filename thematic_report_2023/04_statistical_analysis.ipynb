{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41f03895-06c6-4416-be0f-b19305fd9cd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import nivapy3 as nivapy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import utils\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061c5208-28b6-414f-9927-01f7db782485",
   "metadata": {},
   "source": [
    "# ICPW Thematic report 2023\n",
    "\n",
    "## Part B: Statistical analysis\n",
    "\n",
    "## 1. User options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e170d8a-f394-4276-b0a4-200b22231526",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parameters of interest for analysis\n",
    "inc_par_list = [\n",
    "    \"SO4_µeq/l\",\n",
    "    \"NO3-N_µeq/l\",\n",
    "    \"Cl_µeq/l\",\n",
    "    \"Ca_µeq/l\",\n",
    "    \"Mg_µeq/l\",\n",
    "    \"CaMg_µeq/l\",\n",
    "    \"H_µeq/l\",\n",
    "    \"SAA_µeq/l\",\n",
    "    \"ANC_µeq/l\",\n",
    "    \"OrgAnions_µeq/l\",\n",
    "    \"HCO3_µeq/l\",\n",
    "    \"TOC_mg C/l\",\n",
    "]\n",
    "\n",
    "par_list = [\n",
    "    \"ALK_mmol/l\",\n",
    "    \"ALK-E_µEq/l\",\n",
    "    \"Al_µg/l\",\n",
    "    \"Fe_µg/l\",\n",
    "    \"KOND_mS/m\",\n",
    "    \"LAL_µg/l\",\n",
    "    \"SiO2_mg SiO2/l\",\n",
    "    \"TOC_mg C/l\",\n",
    "    \"TOTN_µg/l N\",\n",
    "    \"TOTP_µg/l P\",\n",
    "    \"SO4_µeq/l\",\n",
    "    \"NO3-N_µeq/l\",\n",
    "    \"NH4-N_µeq/l\",\n",
    "    \"Cl_µeq/l\",\n",
    "    \"Ca_µeq/l\",\n",
    "    \"Mg_µeq/l\",\n",
    "    \"Na_µeq/l\",\n",
    "    \"K_µeq/l\",\n",
    "    \"CaMg_µeq/l\",\n",
    "    \"H_µeq/l\",\n",
    "    \"SAA_µeq/l\",\n",
    "    \"ANC_µeq/l\",\n",
    "    \"OrgAnions_µeq/l\",\n",
    "    \"HCO3_µeq/l\",\n",
    "]\n",
    "\n",
    "# Periods to consider\n",
    "periods = ((1990, 2020), (1990, 2004), (1998, 2012), (2006, 2020))\n",
    "\n",
    "# Whether to let the number of sites vary by time period\n",
    "vary_sites = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dd21d5-4d44-4d70-9251-e9845ca29d05",
   "metadata": {},
   "source": [
    "## 2. Read raw data\n",
    "\n",
    "A basic dataset was compiled in the previous notebook.\n",
    "\n",
    "**Note:** We have decided not to allow availability of NH4 data to limit the site selection, as it restricts the dataset unnecessarily. See the comment [here](https://github.com/JamesSample/icpw2/issues/4#issuecomment-1521958990) and reply [here](https://github.com/JamesSample/icpw2/issues/4#issuecomment-1522126141)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e1f0ec4-f7ce-45f9-82c4-6862c82a7268",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13673/3527533999.py:10: FutureWarning: The default value of numeric_only in DataFrameGroupBy.median is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  wc_df = wc_df.groupby([\"station_id\", \"year\"]).median().reset_index()\n"
     ]
    }
   ],
   "source": [
    "# Station propertiess\n",
    "xl_path = r\"../../../all_icpw_sites_mar_2023.xlsx\"\n",
    "stn_df = pd.read_excel(xl_path, sheet_name=\"all_icpw_stns\")\n",
    "\n",
    "# Median annual chemistry\n",
    "csv_path = r\"./data/thematic_report_2023_working_data.csv\"\n",
    "wc_df = pd.read_csv(csv_path, encoding=\"utf-8\")\n",
    "wc_df[\"sample_date\"] = pd.to_datetime(wc_df[\"sample_date\"], format=\"%Y-%m-%d\")\n",
    "wc_df[\"year\"] = wc_df[\"sample_date\"].dt.year\n",
    "wc_df = wc_df.groupby([\"station_id\", \"year\"]).median().reset_index()\n",
    "wc_df = wc_df[[\"station_id\", \"year\"] + par_list]\n",
    "\n",
    "# Selection criteria\n",
    "csv_path = r\"./data/selection_criteria_by_station-par-period.csv\"\n",
    "inc_df = pd.read_csv(csv_path, encoding=\"utf-8\")\n",
    "inc_df = inc_df[[\"station_id\", \"period\"] + inc_par_list]\n",
    "inc_df.set_index([\"station_id\", \"period\"], inplace=True)\n",
    "inc_df[inc_df == 0] = np.nan\n",
    "inc_df.dropna(how=\"any\", inplace=True)\n",
    "inc_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d3673f2-10a0-482c-895d-099a12e778f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1990-2020:   421 sites.\n",
      "1990-2004:   439 sites.\n",
      "1998-2012:   457 sites.\n",
      "2006-2020:   441 sites.\n",
      "All periods: 403 sites.\n"
     ]
    }
   ],
   "source": [
    "# Print number of stations per period with complete data\n",
    "for period in periods:\n",
    "    st_yr, end_yr = period\n",
    "    inc_df_per = inc_df.query(f\"period == '{st_yr}-{end_yr}'\").copy()\n",
    "    print(f\"{st_yr}-{end_yr}:  \", len(inc_df_per), \"sites.\")\n",
    "\n",
    "# Number of stations that have complete data for ALL periods\n",
    "print(\n",
    "    \"All periods:\",\n",
    "    len(inc_df.groupby([\"station_id\"])[[\"period\"]].count().query(\"period == 4\")),\n",
    "    \"sites.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbc24b0-3f20-44e6-9b19-e7b6f628f67b",
   "metadata": {},
   "source": [
    "After conversation with Rolf, we have decided to consider two datasets:\n",
    "\n",
    " 1. Use the same site selection for all periods i.e. to focus on the 403 sites, and\n",
    " \n",
    " 2. Allow the selection to change in each period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f7f462a-4943-4215-8772-562bd4dab704",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13673/3697588091.py:16: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  sel_stn_gdf.to_file(stn_shp, index=False)\n"
     ]
    }
   ],
   "source": [
    "# Export 403 sites as shapefile for mapping\n",
    "stn_list = (\n",
    "    inc_df.groupby([\"station_id\"])[[\"period\"]]\n",
    "    .count()\n",
    "    .query(\"period == 4\")\n",
    "    .index.tolist()\n",
    ")\n",
    "sel_stn_df = stn_df.query(\"station_id in @stn_list\")\n",
    "sel_stn_gdf = gpd.GeoDataFrame(\n",
    "    sel_stn_df,\n",
    "    geometry=gpd.points_from_xy(\n",
    "        sel_stn_df[\"longitude\"], sel_stn_df[\"latitude\"], crs=\"epsg:4326\"\n",
    "    ),\n",
    ")\n",
    "stn_shp = r\"./results/gis/vector/selected_stations.shp\"\n",
    "sel_stn_gdf.to_file(stn_shp, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1e0372-9307-4360-82c8-9a63146a18d6",
   "metadata": {},
   "source": [
    "## 3. Site-specific trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19c65f39-66f3-4939-b848-8b885037ce0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "res_dict = {\n",
    "    \"period\": [],\n",
    "    \"station_id\": [],\n",
    "    \"variable\": [],\n",
    "    \"n_vals\": [],\n",
    "    \"first\": [],\n",
    "    \"last\": [],\n",
    "    \"mean\": [],\n",
    "    \"median\": [],\n",
    "    \"std_dev\": [],\n",
    "    \"iqr\": [],\n",
    "    \"mk_p_val\": [],\n",
    "    \"mk_trend\": [],\n",
    "    \"sen_slp\": [],\n",
    "    \"sen_incpt\": [],\n",
    "    \"sen_trend\": [],\n",
    "}\n",
    "\n",
    "stn_list = (\n",
    "    inc_df.groupby([\"station_id\"])[[\"period\"]]\n",
    "    .count()\n",
    "    .query(\"period == 4\")\n",
    "    .index.tolist()\n",
    ")\n",
    "\n",
    "if vary_sites:\n",
    "    res_fold = f\"./results/nsites_varying\"\n",
    "else:\n",
    "    res_fold = f\"./results/nsites_fixed\"\n",
    "\n",
    "for period in periods:\n",
    "    st_yr, end_yr = period\n",
    "\n",
    "    # Allow sites to vary by period, if desired\n",
    "    if vary_sites:\n",
    "        inc_df_per = inc_df.query(f\"period == '{st_yr}-{end_yr}'\").copy()\n",
    "        stn_list = list(inc_df_per[\"station_id\"].unique())\n",
    "\n",
    "    # Get data that meet selection criteria for all parameters of interest\n",
    "    df_per = wc_df.query(\n",
    "        \"(station_id in @stn_list) and (@st_yr <= year <= @end_yr)\"\n",
    "    ).copy()\n",
    "\n",
    "    for stn_id in stn_list:\n",
    "        stn_code = stn_df.query(\"station_id == @stn_id\")[\"station_code\"].iloc[0]\n",
    "        stn_name = stn_df.query(\"station_id == @stn_id\")[\"station_name\"].iloc[0]\n",
    "        df = df_per.query(\"station_id == @stn_id\").copy()\n",
    "        del df[\"station_id\"]\n",
    "        df.set_index(\"year\", inplace=True)\n",
    "        df.sort_index(inplace=True)\n",
    "\n",
    "        # Setup plot\n",
    "        if (st_yr == 1990) and (end_yr == 2020):\n",
    "            fig, axes = plt.subplots(nrows=6, ncols=4, figsize=(12, 16))\n",
    "            axes = axes.flatten()\n",
    "\n",
    "        for idx, par in enumerate(sorted(par_list)):\n",
    "            # Mann-Kendall and Sen's slope\n",
    "            par_df = df.dropna(subset=[par])\n",
    "            if len(par_df) > 1:\n",
    "                mk_df = nivapy.stats.mk_test(par_df, par)\n",
    "                res_df, sen_df = nivapy.stats.sens_slope(\n",
    "                    par_df,\n",
    "                    value_col=par,\n",
    "                    index_col=par_df.index,\n",
    "                )\n",
    "\n",
    "                # Add results to dict\n",
    "                res_dict[\"period\"].append(f\"{st_yr}-{end_yr}\")\n",
    "                res_dict[\"station_id\"].append(stn_id)\n",
    "                res_dict[\"variable\"].append(par)\n",
    "\n",
    "                res_dict[\"n_vals\"].append(len(par_df))\n",
    "                res_dict[\"first\"].append(df[par].dropna().iloc[0])\n",
    "                res_dict[\"last\"].append(df[par].dropna().iloc[-1])\n",
    "                res_dict[\"mean\"].append(df[par].mean())\n",
    "                res_dict[\"median\"].append(df[par].median())\n",
    "                res_dict[\"std_dev\"].append(df[par].std())\n",
    "                res_dict[\"iqr\"].append(df[par].quantile(0.75) - df[par].quantile(0.25))\n",
    "\n",
    "                res_dict[\"mk_p_val\"].append(mk_df.loc[\"p\"].value)\n",
    "                res_dict[\"mk_trend\"].append(mk_df.loc[\"trend\"].value)\n",
    "\n",
    "                sslp = res_df.loc[\"sslp\"].value\n",
    "                sincpt = res_df.loc[\"icpt\"].value\n",
    "                res_dict[\"sen_slp\"].append(sslp)\n",
    "                res_dict[\"sen_incpt\"].append(sincpt)\n",
    "                res_dict[\"sen_trend\"].append(res_df.loc[\"trend\"].value)\n",
    "\n",
    "                if (st_yr == 1990) and (end_yr == 2020):\n",
    "                    if res_df.loc[\"trend\"].value == \"no trend\":\n",
    "                        line_col = \"k\"\n",
    "                    else:\n",
    "                        line_col = \"r\"\n",
    "                    axes[idx].plot(sen_df.index, sen_df[par].values, \"bo-\")\n",
    "                    axes[idx].plot(sen_df.index, sen_df.index * sslp + sincpt, line_col)\n",
    "            axes[idx].set_title(par)\n",
    "            axes[idx].set_xlim((st_yr, end_yr))\n",
    "\n",
    "        if (st_yr == 1990) and (end_yr == 2020):\n",
    "            plt.suptitle(f\"{stn_code} ({stn_name})\\n\", fontsize=20)\n",
    "            # plt.subplots_adjust(hspace=0.2)\n",
    "            plt.tight_layout()\n",
    "            png_path = os.path.join(\n",
    "                res_fold, f\"trends_by_site/stn_{stn_id}_{st_yr}-{end_yr}.png\"\n",
    "            )\n",
    "            plt.savefig(png_path, dpi=200)\n",
    "            plt.close()\n",
    "\n",
    "res_df = pd.DataFrame(res_dict)\n",
    "csv_path = os.path.join(res_fold, f\"trends_by_site.csv\")\n",
    "res_df.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a473fc2b-69bf-41d3-a0fe-78fe00f583db",
   "metadata": {},
   "source": [
    "## 4. Regional trends\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c15b15a-4721-4016-ab30-da80a3582722",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "res_dict = {\n",
    "    \"period\": [],\n",
    "    \"region\": [],\n",
    "    \"variable\": [],\n",
    "    \"n_vals\": [],\n",
    "    \"mean\": [],\n",
    "    \"median\": [],\n",
    "    \"std_dev\": [],\n",
    "    \"iqr\": [],\n",
    "    \"mk_p_val\": [],\n",
    "    \"mk_trend\": [],\n",
    "    \"sen_slp\": [],\n",
    "}\n",
    "\n",
    "stn_list = (\n",
    "    inc_df.groupby([\"station_id\"])[[\"period\"]]\n",
    "    .count()\n",
    "    .query(\"period == 4\")\n",
    "    .index.tolist()\n",
    ")\n",
    "\n",
    "if vary_sites:\n",
    "    res_fold = f\"./results/nsites_varying\"\n",
    "else:\n",
    "    res_fold = f\"./results/nsites_fixed\"\n",
    "\n",
    "for period in periods:\n",
    "    st_yr, end_yr = period\n",
    "\n",
    "    # Allow sites to vary by period, if desired\n",
    "    if vary_sites:\n",
    "        inc_df_per = inc_df.query(f\"period == '{st_yr}-{end_yr}'\").copy()\n",
    "        stn_list = list(inc_df_per[\"station_id\"].unique())\n",
    "\n",
    "    # Get data that meet selection criteria for all parameters of interest\n",
    "    df_per = wc_df.query(\n",
    "        \"(station_id in @stn_list) and (@st_yr <= year <= @end_yr)\"\n",
    "    ).copy()\n",
    "\n",
    "    df_per = pd.merge(\n",
    "        df_per, stn_df[[\"station_id\", \"region\"]], how=\"left\", on=\"station_id\"\n",
    "    )\n",
    "    for reg in df_per[\"region\"].unique():\n",
    "        df = df_per.query(\"region == @reg\").copy()\n",
    "        for par in sorted(par_list):\n",
    "            # All sites need at least two data points\n",
    "            par_df = df.dropna(subset=[par])\n",
    "            val_counts = par_df['station_id'].value_counts()\n",
    "            sites_gt1_sample_list = list(val_counts[val_counts > 1].index)\n",
    "            par_df = par_df.query(\"station_id in @sites_gt1_sample_list\")           \n",
    "            \n",
    "            if len(par_df) > 1:\n",
    "                stat_df = nivapy.stats.seasonal_regional_mk_sen(\n",
    "                    par_df,\n",
    "                    time_col=\"year\",\n",
    "                    value_col=par,\n",
    "                    block_col=\"station_id\",\n",
    "                    alpha=0.05,\n",
    "                )\n",
    "\n",
    "                # Add results to dict\n",
    "                res_dict[\"period\"].append(f\"{st_yr}-{end_yr}\")\n",
    "                res_dict[\"region\"].append(reg)\n",
    "                res_dict[\"variable\"].append(par)\n",
    "\n",
    "                res_dict[\"n_vals\"].append(len(par_df))\n",
    "                res_dict[\"mean\"].append(df[par].mean())\n",
    "                res_dict[\"median\"].append(df[par].median())\n",
    "                res_dict[\"std_dev\"].append(df[par].std())\n",
    "                res_dict[\"iqr\"].append(df[par].quantile(0.75) - df[par].quantile(0.25))\n",
    "\n",
    "                res_dict[\"mk_p_val\"].append(stat_df.loc[\"p\"].value)\n",
    "                res_dict[\"mk_trend\"].append(stat_df.loc[\"trend\"].value)\n",
    "                res_dict[\"sen_slp\"].append(stat_df.loc[\"sslp\"].value)\n",
    "\n",
    "res_df = pd.DataFrame(res_dict)\n",
    "csv_path = os.path.join(res_fold, f\"trends_by_region.csv\")\n",
    "res_df.to_csv(csv_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
